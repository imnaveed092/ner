{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, get_dataset_config_names\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_data_subset = get_dataset_config_names(\"xtreme\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ner_data_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAN-X.af',\n",
       " 'PAN-X.ar',\n",
       " 'PAN-X.bg',\n",
       " 'PAN-X.bn',\n",
       " 'PAN-X.de',\n",
       " 'PAN-X.el',\n",
       " 'PAN-X.en',\n",
       " 'PAN-X.es',\n",
       " 'PAN-X.et',\n",
       " 'PAN-X.eu',\n",
       " 'PAN-X.fa',\n",
       " 'PAN-X.fi',\n",
       " 'PAN-X.fr',\n",
       " 'PAN-X.he',\n",
       " 'PAN-X.hi',\n",
       " 'PAN-X.hu',\n",
       " 'PAN-X.id',\n",
       " 'PAN-X.it',\n",
       " 'PAN-X.ja',\n",
       " 'PAN-X.jv',\n",
       " 'PAN-X.ka',\n",
       " 'PAN-X.kk',\n",
       " 'PAN-X.ko',\n",
       " 'PAN-X.ml',\n",
       " 'PAN-X.mr',\n",
       " 'PAN-X.ms',\n",
       " 'PAN-X.my',\n",
       " 'PAN-X.nl',\n",
       " 'PAN-X.pt',\n",
       " 'PAN-X.ru',\n",
       " 'PAN-X.sw',\n",
       " 'PAN-X.ta',\n",
       " 'PAN-X.te',\n",
       " 'PAN-X.th',\n",
       " 'PAN-X.tl',\n",
       " 'PAN-X.tr',\n",
       " 'PAN-X.ur',\n",
       " 'PAN-X.vi',\n",
       " 'PAN-X.yo',\n",
       " 'PAN-X.zh']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_subests = [s for s in ner_data_subset if s.startswith(\"PAN\")]\n",
    "panx_subests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xtreme/PAN-X.en to C:/Users/shiva/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 234M/234M [01:56<00:00, 2.01MB/s] \n",
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xtreme downloaded and prepared to C:/Users/shiva/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 16.37it/s]\n"
     ]
    }
   ],
   "source": [
    "en = load_dataset(\"xtreme\", name=\"PAN-X.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>R.H.</td>\n",
       "      <td>Saunders</td>\n",
       "      <td>(</td>\n",
       "      <td>St.</td>\n",
       "      <td>Lawrence</td>\n",
       "      <td>River</td>\n",
       "      <td>)</td>\n",
       "      <td>(</td>\n",
       "      <td>968</td>\n",
       "      <td>MW</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_tags</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>langs</th>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1   2    3         4      5   6   7    8   9   10\n",
       "tokens    R.H.  Saunders   (  St.  Lawrence  River   )   (  968  MW   )\n",
       "ner_tags     3         4   0    3         4      4   0   0    0   0   0\n",
       "langs       en        en  en   en        en     en  en  en   en  en  en"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(en[\"train\"][0]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en[\"train\"].features[\"ner_tags\"].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>langs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[R.H., Saunders, (, St., Lawrence, River, ), (...</td>\n",
       "      <td>[3, 4, 0, 3, 4, 4, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[;, ', '', Anders, Lindström, '', ']</td>\n",
       "      <td>[0, 0, 0, 1, 2, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Karl, Ove, Knausgård, (, born, 1968, )]</td>\n",
       "      <td>[1, 2, 2, 0, 0, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Atlantic, City, ,, New, Jersey]</td>\n",
       "      <td>[5, 6, 6, 6, 6]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Her, daughter, from, the, second, marriage, w...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en, en, en, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>[Cicely, Courtneidge, ,, Ernest, Truex]</td>\n",
       "      <td>[1, 2, 0, 1, 2]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>[Aracaju, ,, Sergipe, ,, Brazil]</td>\n",
       "      <td>[5, 0, 5, 0, 5]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>[Louisville, in, the, American, Civil, War]</td>\n",
       "      <td>[5, 6, 6, 6, 6, 6]</td>\n",
       "      <td>[en, en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>[16, (, David, Nugent, )]</td>\n",
       "      <td>[0, 0, 1, 2, 0]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>[List, of, regional, mammals, lists]</td>\n",
       "      <td>[3, 4, 4, 4, 4]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [R.H., Saunders, (, St., Lawrence, River, ), (...   \n",
       "1                   [;, ', '', Anders, Lindström, '', ']   \n",
       "2               [Karl, Ove, Knausgård, (, born, 1968, )]   \n",
       "3                       [Atlantic, City, ,, New, Jersey]   \n",
       "4      [Her, daughter, from, the, second, marriage, w...   \n",
       "...                                                  ...   \n",
       "19995            [Cicely, Courtneidge, ,, Ernest, Truex]   \n",
       "19996                   [Aracaju, ,, Sergipe, ,, Brazil]   \n",
       "19997        [Louisville, in, the, American, Civil, War]   \n",
       "19998                          [16, (, David, Nugent, )]   \n",
       "19999               [List, of, regional, mammals, lists]   \n",
       "\n",
       "                                                ner_tags  \\\n",
       "0                      [3, 4, 0, 3, 4, 4, 0, 0, 0, 0, 0]   \n",
       "1                                  [0, 0, 0, 1, 2, 0, 0]   \n",
       "2                                  [1, 2, 2, 0, 0, 0, 0]   \n",
       "3                                        [5, 6, 6, 6, 6]   \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "19995                                    [1, 2, 0, 1, 2]   \n",
       "19996                                    [5, 0, 5, 0, 5]   \n",
       "19997                                 [5, 6, 6, 6, 6, 6]   \n",
       "19998                                    [0, 0, 1, 2, 0]   \n",
       "19999                                    [3, 4, 4, 4, 4]   \n",
       "\n",
       "                                                   langs  \n",
       "0           [en, en, en, en, en, en, en, en, en, en, en]  \n",
       "1                           [en, en, en, en, en, en, en]  \n",
       "2                           [en, en, en, en, en, en, en]  \n",
       "3                                   [en, en, en, en, en]  \n",
       "4      [en, en, en, en, en, en, en, en, en, en, en, e...  \n",
       "...                                                  ...  \n",
       "19995                               [en, en, en, en, en]  \n",
       "19996                               [en, en, en, en, en]  \n",
       "19997                           [en, en, en, en, en, en]  \n",
       "19998                               [en, en, en, en, en]  \n",
       "19999                               [en, en, en, en, en]  \n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(en[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>langs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Shortly, afterward, ,, an, encouraging, respo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, ...</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en, en, en, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[:, Kanye, West, featuring, Jamie, Foxx, —, ``...</td>\n",
       "      <td>[0, 1, 2, 0, 1, 2, 0, 0, 3, 4, 0, 0, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en, en, en, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Blacktown, railway, station]</td>\n",
       "      <td>[3, 4, 4]</td>\n",
       "      <td>[en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['', Mycalesis, perseus, lalassis, '', (, Hewi...</td>\n",
       "      <td>[0, 5, 6, 6, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Jonny, Lee, Miller, -, Eli, Stone, '']</td>\n",
       "      <td>[1, 2, 2, 0, 3, 4, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>[Tony, Stewart, ', '', (, PC4, ), ', '']</td>\n",
       "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>[Maryland, Route, 472]</td>\n",
       "      <td>[3, 4, 4]</td>\n",
       "      <td>[en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>[Renton, ,, Washington]</td>\n",
       "      <td>[5, 6, 6]</td>\n",
       "      <td>[en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>[He, served, as, a, member, of, the, South, Ea...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>[|, align=left|, Free, Australia, Party]</td>\n",
       "      <td>[0, 0, 3, 4, 4]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens  \\\n",
       "0     [Shortly, afterward, ,, an, encouraging, respo...   \n",
       "1     [:, Kanye, West, featuring, Jamie, Foxx, —, ``...   \n",
       "2                         [Blacktown, railway, station]   \n",
       "3     ['', Mycalesis, perseus, lalassis, '', (, Hewi...   \n",
       "4               [Jonny, Lee, Miller, -, Eli, Stone, '']   \n",
       "...                                                 ...   \n",
       "9995           [Tony, Stewart, ', '', (, PC4, ), ', '']   \n",
       "9996                             [Maryland, Route, 472]   \n",
       "9997                            [Renton, ,, Washington]   \n",
       "9998  [He, served, as, a, member, of, the, South, Ea...   \n",
       "9999           [|, align=left|, Free, Australia, Party]   \n",
       "\n",
       "                                               ner_tags  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, ...   \n",
       "1            [0, 1, 2, 0, 1, 2, 0, 0, 3, 4, 0, 0, 0, 0]   \n",
       "2                                             [3, 4, 4]   \n",
       "3                        [0, 5, 6, 6, 0, 0, 0, 0, 0, 0]   \n",
       "4                                 [1, 2, 2, 0, 3, 4, 0]   \n",
       "...                                                 ...   \n",
       "9995                        [1, 2, 0, 0, 0, 0, 0, 0, 0]   \n",
       "9996                                          [3, 4, 4]   \n",
       "9997                                          [5, 6, 6]   \n",
       "9998                  [0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0]   \n",
       "9999                                    [0, 0, 3, 4, 4]   \n",
       "\n",
       "                                                  langs  \n",
       "0     [en, en, en, en, en, en, en, en, en, en, en, e...  \n",
       "1     [en, en, en, en, en, en, en, en, en, en, en, e...  \n",
       "2                                          [en, en, en]  \n",
       "3              [en, en, en, en, en, en, en, en, en, en]  \n",
       "4                          [en, en, en, en, en, en, en]  \n",
       "...                                                 ...  \n",
       "9995               [en, en, en, en, en, en, en, en, en]  \n",
       "9996                                       [en, en, en]  \n",
       "9997                                       [en, en, en]  \n",
       "9998       [en, en, en, en, en, en, en, en, en, en, en]  \n",
       "9999                               [en, en, en, en, en]  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(en[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>langs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Sioux, Falls, Arena, (, Sioux, Falls, ,, Sout...</td>\n",
       "      <td>[3, 4, 4, 0, 5, 6, 6, 6, 6, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[George, Randolph, Hearst, ,, Jr, .]</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[en, en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Conch, Key, ,, Florida]</td>\n",
       "      <td>[5, 6, 6, 6]</td>\n",
       "      <td>[en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Fairground]], '', by, Simply, Red, '', Bad, R...</td>\n",
       "      <td>[0, 0, 0, 3, 4, 0, 3, 4, 0, 0, 1, 2]</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The, Game]], ,, Ice, Cube, ,, Dr., Dre]</td>\n",
       "      <td>[0, 0, 0, 1, 2, 0, 1, 2]</td>\n",
       "      <td>[en, en, en, en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>[Middleborough, ,, Massachusetts]</td>\n",
       "      <td>[5, 6, 6]</td>\n",
       "      <td>[en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>['', Kalmar, Union, '', ']</td>\n",
       "      <td>[0, 5, 6, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>[At, the, end, of, November, ,, it, became, pa...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en, en, en, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>[**, County, of, Bentheim-Steinfurt, –, Karl, ...</td>\n",
       "      <td>[0, 3, 4, 4, 0, 3, 4, 4, 0, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>[Tomb, Raider, :, Definitive, Edition, '']</td>\n",
       "      <td>[3, 4, 4, 4, 4, 0]</td>\n",
       "      <td>[en, en, en, en, en, en]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens  \\\n",
       "0     [Sioux, Falls, Arena, (, Sioux, Falls, ,, Sout...   \n",
       "1                  [George, Randolph, Hearst, ,, Jr, .]   \n",
       "2                              [Conch, Key, ,, Florida]   \n",
       "3     [Fairground]], '', by, Simply, Red, '', Bad, R...   \n",
       "4              [The, Game]], ,, Ice, Cube, ,, Dr., Dre]   \n",
       "...                                                 ...   \n",
       "9995                  [Middleborough, ,, Massachusetts]   \n",
       "9996                         ['', Kalmar, Union, '', ']   \n",
       "9997  [At, the, end, of, November, ,, it, became, pa...   \n",
       "9998  [**, County, of, Bentheim-Steinfurt, –, Karl, ...   \n",
       "9999         [Tomb, Raider, :, Definitive, Edition, '']   \n",
       "\n",
       "                                        ner_tags  \\\n",
       "0                 [3, 4, 4, 0, 5, 6, 6, 6, 6, 0]   \n",
       "1                             [1, 2, 2, 2, 2, 2]   \n",
       "2                                   [5, 6, 6, 6]   \n",
       "3           [0, 0, 0, 3, 4, 0, 3, 4, 0, 0, 1, 2]   \n",
       "4                       [0, 0, 0, 1, 2, 0, 1, 2]   \n",
       "...                                          ...   \n",
       "9995                                   [5, 6, 6]   \n",
       "9996                             [0, 5, 6, 0, 0]   \n",
       "9997  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0]   \n",
       "9998           [0, 3, 4, 4, 0, 3, 4, 4, 0, 0, 0]   \n",
       "9999                          [3, 4, 4, 4, 4, 0]   \n",
       "\n",
       "                                                  langs  \n",
       "0              [en, en, en, en, en, en, en, en, en, en]  \n",
       "1                              [en, en, en, en, en, en]  \n",
       "2                                      [en, en, en, en]  \n",
       "3      [en, en, en, en, en, en, en, en, en, en, en, en]  \n",
       "4                      [en, en, en, en, en, en, en, en]  \n",
       "...                                                 ...  \n",
       "9995                                       [en, en, en]  \n",
       "9996                               [en, en, en, en, en]  \n",
       "9997  [en, en, en, en, en, en, en, en, en, en, en, e...  \n",
       "9998       [en, en, en, en, en, en, en, en, en, en, en]  \n",
       "9999                           [en, en, en, en, en, en]  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(en[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None),\n",
       " 'langs': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en['train'].features['ner_tags'].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[';', \"'\", \"''\", 'Anders', 'Lindström', \"''\", \"'\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en['train'][1]['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en['train'][1]['tokens'].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 2, 0, 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en['train'][1]['ner_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en['train'].features['ner_tags'].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n",
      "ner_tags: Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)\n",
      "langs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n"
     ]
    }
   ],
   "source": [
    "for key, value in en['train'].features.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:03<00:00, 5427.47ex/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 6589.07ex/s]\n",
      "100%|██████████| 10000/10000 [00:02<00:00, 3663.46ex/s]\n"
     ]
    }
   ],
   "source": [
    "tags = en['train'].features['ner_tags'].feature\n",
    "print(tags)\n",
    "\n",
    "def create_tag_names(batch):\n",
    "    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch['ner_tags']]}\n",
    "\n",
    "new_en = en.map(create_tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>List</td>\n",
       "      <td>of</td>\n",
       "      <td>years</td>\n",
       "      <td>in</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_tags</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_tags_str</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0      1      2      3       4\n",
       "Tokens         List     of  years     in  Brazil\n",
       "ner_tags          3      4      4      4       4\n",
       "ner_tags_str  B-ORG  I-ORG  I-ORG  I-ORG   I-ORG"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_example = new_en[\"train\"][100]\n",
    "pd.DataFrame([de_example[\"tokens\"],de_example[\"ner_tags\"] ,de_example[\"ner_tags_str\"]],\n",
    "['Tokens',\"ner_tags\" ,'ner_tags_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>langs</th>\n",
       "      <th>ner_tags_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[R.H., Saunders, (, St., Lawrence, River, ), (...</td>\n",
       "      <td>[3, 4, 0, 3, 4, 4, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en, en, en]</td>\n",
       "      <td>[B-ORG, I-ORG, O, B-ORG, I-ORG, I-ORG, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[;, ', '', Anders, Lindström, '', ']</td>\n",
       "      <td>[0, 0, 0, 1, 2, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en]</td>\n",
       "      <td>[O, O, O, B-PER, I-PER, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Karl, Ove, Knausgård, (, born, 1968, )]</td>\n",
       "      <td>[1, 2, 2, 0, 0, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en]</td>\n",
       "      <td>[B-PER, I-PER, I-PER, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Atlantic, City, ,, New, Jersey]</td>\n",
       "      <td>[5, 6, 6, 6, 6]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "      <td>[B-LOC, I-LOC, I-LOC, I-LOC, I-LOC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Her, daughter, from, the, second, marriage, w...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en, en, en, e...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-PER, I-PER, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>[Cicely, Courtneidge, ,, Ernest, Truex]</td>\n",
       "      <td>[1, 2, 0, 1, 2]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "      <td>[B-PER, I-PER, O, B-PER, I-PER]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>[Aracaju, ,, Sergipe, ,, Brazil]</td>\n",
       "      <td>[5, 0, 5, 0, 5]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "      <td>[B-LOC, O, B-LOC, O, B-LOC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>[Louisville, in, the, American, Civil, War]</td>\n",
       "      <td>[5, 6, 6, 6, 6, 6]</td>\n",
       "      <td>[en, en, en, en, en, en]</td>\n",
       "      <td>[B-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>[16, (, David, Nugent, )]</td>\n",
       "      <td>[0, 0, 1, 2, 0]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "      <td>[O, O, B-PER, I-PER, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>[List, of, regional, mammals, lists]</td>\n",
       "      <td>[3, 4, 4, 4, 4]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "      <td>[B-ORG, I-ORG, I-ORG, I-ORG, I-ORG]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [R.H., Saunders, (, St., Lawrence, River, ), (...   \n",
       "1                   [;, ', '', Anders, Lindström, '', ']   \n",
       "2               [Karl, Ove, Knausgård, (, born, 1968, )]   \n",
       "3                       [Atlantic, City, ,, New, Jersey]   \n",
       "4      [Her, daughter, from, the, second, marriage, w...   \n",
       "...                                                  ...   \n",
       "19995            [Cicely, Courtneidge, ,, Ernest, Truex]   \n",
       "19996                   [Aracaju, ,, Sergipe, ,, Brazil]   \n",
       "19997        [Louisville, in, the, American, Civil, War]   \n",
       "19998                          [16, (, David, Nugent, )]   \n",
       "19999               [List, of, regional, mammals, lists]   \n",
       "\n",
       "                                                ner_tags  \\\n",
       "0                      [3, 4, 0, 3, 4, 4, 0, 0, 0, 0, 0]   \n",
       "1                                  [0, 0, 0, 1, 2, 0, 0]   \n",
       "2                                  [1, 2, 2, 0, 0, 0, 0]   \n",
       "3                                        [5, 6, 6, 6, 6]   \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "19995                                    [1, 2, 0, 1, 2]   \n",
       "19996                                    [5, 0, 5, 0, 5]   \n",
       "19997                                 [5, 6, 6, 6, 6, 6]   \n",
       "19998                                    [0, 0, 1, 2, 0]   \n",
       "19999                                    [3, 4, 4, 4, 4]   \n",
       "\n",
       "                                                   langs  \\\n",
       "0           [en, en, en, en, en, en, en, en, en, en, en]   \n",
       "1                           [en, en, en, en, en, en, en]   \n",
       "2                           [en, en, en, en, en, en, en]   \n",
       "3                                   [en, en, en, en, en]   \n",
       "4      [en, en, en, en, en, en, en, en, en, en, en, e...   \n",
       "...                                                  ...   \n",
       "19995                               [en, en, en, en, en]   \n",
       "19996                               [en, en, en, en, en]   \n",
       "19997                           [en, en, en, en, en, en]   \n",
       "19998                               [en, en, en, en, en]   \n",
       "19999                               [en, en, en, en, en]   \n",
       "\n",
       "                                            ner_tags_str  \n",
       "0      [B-ORG, I-ORG, O, B-ORG, I-ORG, I-ORG, O, O, O...  \n",
       "1                          [O, O, O, B-PER, I-PER, O, O]  \n",
       "2                      [B-PER, I-PER, I-PER, O, O, O, O]  \n",
       "3                    [B-LOC, I-LOC, I-LOC, I-LOC, I-LOC]  \n",
       "4      [O, O, O, O, O, O, O, B-PER, I-PER, O, O, O, O...  \n",
       "...                                                  ...  \n",
       "19995                    [B-PER, I-PER, O, B-PER, I-PER]  \n",
       "19996                        [B-LOC, O, B-LOC, O, B-LOC]  \n",
       "19997         [B-LOC, I-LOC, I-LOC, I-LOC, I-LOC, I-LOC]  \n",
       "19998                            [O, O, B-PER, I-PER, O]  \n",
       "19999                [B-ORG, I-ORG, I-ORG, I-ORG, I-ORG]  \n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(new_en[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xlmr - Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 615/615 [00:00<00:00, 75.9kB/s]\n",
      "c:\\Users\\shiva\\Desktop\\NER Project\\NER-Project\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\shiva\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading: 100%|██████████| 5.07M/5.07M [00:06<00:00, 780kB/s] \n",
      "Downloading: 100%|██████████| 9.10M/9.10M [00:03<00:00, 2.52MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "959e4ee04a2991b89d8f12f9443b7be8c0876601bac9704c3626b7438929f648"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
